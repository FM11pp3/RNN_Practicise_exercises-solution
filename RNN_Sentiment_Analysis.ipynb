{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Sentiment Analysis with Bidirectional LSTM\n",
    "\n",
    "This notebook builds a sentiment classifier for IMDb movie reviews using TensorFlow/Keras. We walk through loading the dataset, preparing padded sequences, training a bidirectional LSTM, and evaluating performance.\n",
    "\n",
    "**Pipeline overview**\n",
    "\n",
    "1. Setup and imports  \n",
    "2. Load and inspect the IMDb dataset  \n",
    "3. Preprocess sequences with padding and exploratory checks  \n",
    "4. Train a bidirectional LSTM baseline  \n",
    "5. Evaluate accuracy and error patterns, then outline next steps\n",
    "\n",
    "Dataset: TensorFlow/Keras IMDb reviews (25k train / 25k test) with integer-encoded tokens sorted by frequency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Configure core libraries, reproducibility seeds, and training hyperparameters used throughout the workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Hyperparameters\n",
    "NUM_WORDS = 10000        # keep the top-N most frequent tokens\n",
    "MAX_LEN = 200            # pad / truncate each review to this length\n",
    "EMBEDDING_DIM = 64\n",
    "LSTM_UNITS = 64\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 12\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect the IMDb Dataset\n",
    "\n",
    "Download the IMDb movie-review dataset limited to the `NUM_WORDS` most frequent tokens. Each review is a sequence of integer token IDs ordered by word frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "(x_train_raw, y_train), (x_test_raw, y_test) = imdb.load_data(num_words=NUM_WORDS, index_from=3)\n",
    "\n",
    "print(f\"Training samples: {len(x_train_raw):,}\")\n",
    "print(f\"Test samples: {len(x_test_raw):,}\")\n",
    "\n",
    "# Reverse dictionary for interpretability\n",
    "word_index = imdb.get_word_index()\n",
    "word_index = {k: (v + 3) for k, v in word_index.items()}\n",
    "word_index['<PAD>'] = 0\n",
    "word_index['<START>'] = 1\n",
    "word_index['<UNK>'] = 2\n",
    "word_index['<UNUSED>'] = 3\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}\n",
    "\n",
    "def decode_review(sequence):\n",
    "    return ' '.join(reverse_word_index.get(i, '?') for i in sequence)\n",
    "\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "print(\"Example decoded review:\")\n",
    "print(decode_review(x_train_raw[0])[:500], \"...\")\n",
    "print(f\"Label: {label_map[y_train[0]]}\")\n",
    "\n",
    "class_distribution = pd.Series(y_train).value_counts().sort_index()\n",
    "print(\"\n",
    "Class distribution (train):\")\n",
    "print(class_distribution.rename(index=label_map))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess: Padding and Exploratory Checks\n",
    "\n",
    "Pad each review to `MAX_LEN` tokens to obtain fixed-length tensors and inspect raw-length statistics to justify the padding choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_lengths = [len(seq) for seq in x_train_raw]\n",
    "test_lengths = [len(seq) for seq in x_test_raw]\n",
    "\n",
    "x_train = pad_sequences(\n",
    "    x_train_raw,\n",
    "    maxlen=MAX_LEN,\n",
    "    padding='post',\n",
    "    truncating='post'\n",
    ")\n",
    "x_test = pad_sequences(\n",
    "    x_test_raw,\n",
    "    maxlen=MAX_LEN,\n",
    "    padding='post',\n",
    "    truncating='post'\n",
    ")\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"Average review length (train): {np.mean(train_lengths):.1f} tokens\")\n",
    "print(f\"95th percentile length: {np.percentile(train_lengths, 95):.0f} tokens\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.hist(train_lengths, bins=40, color='steelblue', alpha=0.7, label='train')\n",
    "ax.axvline(MAX_LEN, color='red', linestyle='--', label=f'MAX_LEN={MAX_LEN}')\n",
    "ax.set_xlabel('Review length (tokens)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of raw review lengths')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the Bidirectional LSTM Model\n",
    "\n",
    "Stack an embedding layer with a bidirectional LSTM to capture contextual information from both directions, then pool and classify with dense layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=NUM_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "    layers.Bidirectional(layers.LSTM(LSTM_UNITS, return_sequences=True)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.GlobalMaxPool1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "Fit the network with early stopping on validation accuracy to reduce overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate and Interpret Results\n",
    "\n",
    "Assess generalisation on the test set, inspect detailed classification metrics, and visualise the confusion matrix. Plot learning curves to understand optimisation behaviour.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "y_pred_prob = model.predict(x_test, verbose=0)\n",
    "y_pred = (y_pred_prob >= 0.5).astype('int32').ravel()\n",
    "\n",
    "print(\"\n",
    "Classification report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['negative', 'positive']))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['pred neg', 'pred pos'])\n",
    "ax.set_yticklabels(['true neg', 'true pos'])\n",
    "ax.set_title('Confusion matrix')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "if history.history.get('accuracy'):\n",
    "    axes[0].plot(history.history['accuracy'], label='train')\n",
    "    axes[0].plot(history.history.get('val_accuracy', []), label='val')\n",
    "    axes[0].set_title('Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'Accuracy not tracked', ha='center')\n",
    "    axes[0].set_axis_off()\n",
    "\n",
    "if history.history.get('loss'):\n",
    "    axes[1].plot(history.history['loss'], label='train')\n",
    "    axes[1].plot(history.history.get('val_loss', []), label='val')\n",
    "    axes[1].set_title('Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'Loss not tracked', ha='center')\n",
    "    axes[1].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(SEED)\n",
    "sample_indices = np.random.choice(len(x_test), size=3, replace=False)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    prob = float(y_pred_prob[idx])\n",
    "    predicted = 'positive' if prob >= 0.5 else 'negative'\n",
    "    actual = label_map[int(y_test[idx])]\n",
    "    print(f\"Review #{idx}\")\n",
    "    print(f\"True: {actual} | Predicted: {predicted} ({prob:.2f})\")\n",
    "    print(decode_review(x_test_raw[idx])[:400], '...')\n",
    "    print('-' * 80)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Explore alternative model architectures (stacked LSTMs, GRUs, or convolutional front-ends) and compare validation metrics.\n",
    "- Increase `NUM_WORDS` or `MAX_LEN` and observe the trade-off between vocabulary coverage and training cost.\n",
    "- Add regularisation such as recurrent dropout or L2 penalties, or incorporate pre-trained word embeddings (e.g., GloVe) for richer representations.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
